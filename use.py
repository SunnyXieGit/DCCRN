import torch
import librosa as lib
import noisereduce as nr
import tkinter as tk
from tkinter import ttk, filedialog
import threading
from tkinterdnd2 import TkinterDnD, DND_FILES
import os
import ffmpeg
import subprocess
#from pydub import AudioSegment
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
from pydub import AudioSegment



class AudioProcessorApp(TkinterDnD.Tk):
    def __init__(self):
        super().__init__()
        self.title("ç½‘è¯¾éŸ³é¢‘é™å™ªå¤„ç†å™¨")
        self.geometry("800x500+500+250")#("å®½åº¦xé«˜åº¦+Xåæ ‡+Yåæ ‡")
        # åˆå§‹åŒ–å…¨å±€æ ·å¼
        self.init_style()
        # æ¨¡å‹é…ç½®å‚æ•°
        self.sr = 16000
        self.model_path = './logs/parameter_epoch1_2025-03-01 18-04-11.pth'
        # self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.device = torch.device("cuda:0")
        self.create_widgets()
        self.load_model()

    def init_style(self):
        """è‡ªå®šä¹‰å…¨å±€ç»„ä»¶æ ·å¼"""
        self.style = ttk.Style()
        # è®¾ç½®å…¨å±€å­—ä½“ï¼ˆå¾®è½¯é›…é»‘ï¼Œ16å·ï¼‰
        self.style.configure(".", font=("Microsoft YaHei", 16))
        # æŒ‰é’®æ ·å¼
        self.style.configure(
            "Big.TButton",
            font=("Microsoft YaHei", 18, "bold"),
            padding=15,
            width=20
        )
        # è¾“å…¥æ¡†æ ·å¼
        self.style.configure(
            "Big.TEntry",
            padding=10,
            font=("Microsoft YaHei", 14)
        )

    def create_widgets(self):
        """åˆ›å»ºç•Œé¢ç»„ä»¶"""
        # ä¸»å®¹å™¨
        main_frame = ttk.Frame(self)
        main_frame.pack(expand=True, fill=tk.BOTH, padx=20, pady=20)

        # æ–‡ä»¶è¾“å…¥åŒºåŸŸ
        input_frame = ttk.LabelFrame(main_frame, text=" è¾“å…¥è®¾ç½® ", padding=(20, 15))
        input_frame.pack(fill=tk.X, pady=10)

        ttk.Label(input_frame, text="éœ€è¦é™å™ªçš„æ–‡ä»¶è·¯å¾„ï¼š").grid(row=0, column=0, sticky=tk.W, padx=5, pady=10)

        self.file_entry = ttk.Entry(
            input_frame,
            width=60,
            style="Big.TEntry"
        )
        self.file_entry.grid(row=1, column=0, columnspan=2, sticky=tk.EW, padx=5, pady=5)

        # æ‹–æ”¾æ”¯æŒ
        self.file_entry.drop_target_register(DND_FILES)
        self.file_entry.dnd_bind('<<Drop>>', self.on_drop)

        # æ“ä½œæŒ‰é’®åŒºåŸŸ
        btn_frame = ttk.Frame(main_frame)
        btn_frame.pack(fill=tk.X, pady=20)

        ttk.Button(
            btn_frame,
            text="ğŸ“ æµè§ˆæœ¬åœ°æ–‡ä»¶",
            command=self.browse_file,
            style="Big.TButton"
        ).pack(side=tk.LEFT, expand=True, padx=10)

        self.process_btn = ttk.Button(
            btn_frame,
            text="âš¡ å¼€å§‹é™å™ªå¤„ç†",
            command=self.start_processing,
            style="Big.TButton"
        )
        self.process_btn.pack(side=tk.LEFT, expand=True, padx=10)

        # çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
        status_frame = ttk.Frame(main_frame)
        status_frame.pack(fill=tk.X, pady=15)

        self.status_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(
            status_frame,
            textvariable=self.status_var,
            font=("Microsoft YaHei", 14, "bold"),
            foreground="#444"
        ).pack(expand=True)

    def load_model(self):
        try:
            self.dccrn_model = torch.load(self.model_path).to(self.device)
            self.dccrn_model.eval()
            if torch.cuda.is_available():
                gpu_info = f"æ£€æµ‹åˆ°æ˜¾å¡ï¼š{torch.cuda.get_device_name(0)}"
            else:
                gpu_info = "è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°å¯ç”¨æ˜¾å¡ï¼"
            self.status_var.set("âœ… æ¨¡å‹è½½å…¥æˆåŠŸï¼"+gpu_info)
        except Exception as e:
            self.status_var.set(f"âŒ æ¨¡å‹è½½å…¥é”™è¯¯: {str(e)}")

    def on_drop(self, event):
        files = event.data.split()
        if files:
            self.file_entry.delete(0, tk.END)
            self.file_entry.insert(0, files[0].strip("{}"))

    def browse_file(self):
        file_path = filedialog.askopenfilename(
            filetypes=[("éŸ³é¢‘æ–‡ä»¶", "*.wav *.mp3")]
        )
        if file_path:
            self.file_entry.delete(0, tk.END)
            self.file_entry.insert(0, file_path)

    def start_processing(self):
        input_path = self.file_entry.get()
        if not input_path:
            self.status_var.set("âš  è¯·å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶ï¼")
            return

        self.process_btn.config(state="disabled")
        self.status_var.set("â³ æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")

        # åœ¨åå°çº¿ç¨‹è¿è¡Œå¤„ç†
        threading.Thread(target=self.process_audio, args=(input_path,)).start()

    def process_audio(self, input_path):
        try:
            # åŠ è½½éŸ³é¢‘
            noisy_audio, _ = lib.load(input_path, sr=self.sr)
            nr_noise = nr.reduce_noise(noisy_audio, sr=self.sr)
            sf.write('./output/nrdenoised_audio.wav', nr_noise, self.sr)

            # FFmpeg éŸ³é‡è°ƒæ•´
            subprocess.run([
                'ffmpeg', '-i', './output/nrdenoised_audio.wav',
                '-filter:a', 'volume=3.0', '-y', './output/fdenoised.wav'
            ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            # ä¿å­˜ç»“æœ
            temp_path = './output/fdenoised.wav'

            """æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹"""
            output_path = os.path.abspath('./output')
            # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨åˆ™åˆ›å»º
            if not os.path.exists(output_path):
                os.makedirs(output_path)
            os.startfile(output_path)
            # äºŒæ¬¡é™å™ªå’ŒéŸ³é‡è°ƒæ•´
            self.post_process(temp_path)
            self.status_var.set("å¤„ç†æˆåŠŸ!")

        except Exception as e:
            self.status_var.set(f"Error: {str(e)}")
        finally:
            self.process_btn.config(state="normal")

    def load_wav(self, signal, frame_dur=37.5):
        print("load_signal", signal.shape)
        win = int(frame_dur / 1000 * self.sr)
        lten = torch.tensor(np.array(np.split(signal, int(len(signal) / win), axis=0)))
        print("lten", lten.shape)
        return lten

    def save_reconstructed_audio(self, output_frames, save_path):
        full_signal = np.concatenate(output_frames, axis=0)
        full_signal = np.clip(full_signal, -1.0, 1.0)
        sf.write(save_path, full_signal.astype(np.float32), self.sr)

    def post_process(self, input_file):
        # äºŒæ¬¡é™å™ªå¤„ç†
        faudio, _ = lib.load(input_file, sr=self.sr)
        # é¢„å¤„ç†
        noisy_audio_tensor = self.load_wav(faudio).float().to(self.device)

        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            clean_audio_tensor = self.dccrn_model(noisy_audio_tensor).to(self.device)
            print("clean_audio_tensor", clean_audio_tensor.shape)
        # åå¤„ç†
        clean_audio = clean_audio_tensor.squeeze(1).cpu().detach().numpy()
        save_path = "./output/final_denoised.wav"
        self.save_reconstructed_audio(clean_audio, save_path)


if __name__ == "__main__":
    app = AudioProcessorApp()
    app.mainloop()







